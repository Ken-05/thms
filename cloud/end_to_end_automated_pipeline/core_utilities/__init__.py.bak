import os
#import shutil
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf  # for gcs file access

# -----------------------------
# Load CSV from GCS or local path
# -----------------------------
def load_csv(path):
    if path.startswith("gs://"):
        with tf.io.gfile.GFile(path, "r") as f:
            df = pd.read_csv(f)
    else:
        df = pd.read_csv(path)
    return df
    
# -----------------------------
# Save DataFrame to GCS or local path
# -----------------------------
def save_csv(df, path):
    if path.startswith("gs://"):
        with tf.io.gfile.GFile(path, "w") as f:
            df.to_csv(f, index=False)
    else:
        df.to_csv(path, index=False)


# -----------------------------
# Feature engineering and labeling (same as before)
# -----------------------------
def feature_engineering(df):
    rolling_cols = [
        "engine_temp_C", "front_brake_temp_C", "rear_brake_temp_C", "alt_temp_C", "clutch_temp_C",
        "hydraulic_level_pct", "transmission_level", "cabin_acX", "cabin_acY", "cabin_acZ",
        "body_frame_abX", "body_frame_abY", "body_frame_abZ", "engine_coolant_temp_C",
        "engine_rpm", "fuel_temp_C"
    ]
    for col in rolling_cols:
        if col in df.columns:
            df[f"{col}_roll_mean_5"] = df[col].rolling(window=5, min_periods=1).mean()
            df[f"{col}_roll_std_5"] = df[col].rolling(window=5, min_periods=1).std().fillna(0)
    for col in rolling_cols:
        if col in df.columns:
            df[f"{col}_delta"] = df[col] - df[col].shift(1)
    delta_cols = [f"{col}_delta" for col in rolling_cols if col in df.columns]
    df[delta_cols] = df[delta_cols].fillna(0)
    return df

def generate_labels(df):
    df['fault_label'] = 0
    temp_col = None
    if 'engine_temp_C' in df.columns:
        temp_col = 'engine_temp_C'
    elif 'engine_coolant_temp_C' in df.columns:
        temp_col = 'engine_coolant_temp_C'
    if temp_col:
        df.loc[df[temp_col] > 90, 'fault_label'] = 1
    if 'hydraulic_level_pct' in df.columns:
        df.loc[df['hydraulic_level_pct'] < 20, 'fault_label'] = 1
    return df

def train_test_data_split(df):
    features = df.drop(columns=['fault_label', 'timestamp'])
    labels = df['fault_label']
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels, test_size=0.2, random_state=42, stratify=labels
    )
    print(f"Train samples: {len(X_train)}, Test samples: {len(X_test)}")
    return X_train, X_test, y_train, y_test

# -----------------------------
# Main preprocess function (now accepts csv_path on GCS or local)
# -----------------------------
def preprocess(csv_path):
    df = load_csv(csv_path)
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

    serial_mask = df['source'] == 'serial'
    can_mask = df['source'] == 'can'

    serial_cols = [
        "timestamp_ms", "engine_temp_C", "front_brake_temp_C", "rear_brake_temp_C", "alt_temp_C",
        "clutch_temp_C", "hydraulic_level_pct", "transmission_level", "cabin_acX", "cabin_acY",
        "cabin_acZ", "body_frame_abX", "body_frame_abY", "body_frame_abZ"
    ]

    def parse_serial_data(row):
        try:
            data_str = row['data']
            values = data_str.split(',')
            if len(values) != len(serial_cols):
                return pd.Series([np.nan]*len(serial_cols))
            return pd.Series(values, index=serial_cols)
        except Exception:
            return pd.Series([np.nan]*len(serial_cols))

    serial_data = df[serial_mask].apply(parse_serial_data, axis=1)
    for col in serial_cols:
        serial_data[col] = pd.to_numeric(serial_data[col], errors='coerce')

    df.loc[serial_mask, serial_cols] = serial_data

    can_numeric_cols = ['engine_coolant_temp_C', 'engine_rpm', 'fuel_temp_C']
    for col in can_numeric_cols:
        df.loc[can_mask, col] = pd.to_numeric(df.loc[can_mask, col], errors='coerce')

    numeric_cols = serial_cols + can_numeric_cols
    for col in numeric_cols:
        if col in df.columns:
            median_val = df[col].median()
            if pd.isna(median_val):
                median_val = 0
            df[col].fillna(median_val, inplace=True)

    df['source'] = df['source'].astype('category').cat.codes
    df['id'] = df['id'].fillna('none')
    df['id'] = df['id'].astype('category').cat.codes

    df.drop(columns=['data', 'raw_line', 'pgn'], inplace=True, errors='ignore')

    df = feature_engineering(df)
    df = generate_labels(df)

    feature_cols = numeric_cols.copy()
    engineered_cols = [col for col in df.columns if any(suffix in col for suffix in ["roll_mean_5", "roll_std_5", "delta"])]
    feature_cols.extend(engineered_cols)
    feature_cols = [col for col in feature_cols if col in df.columns]

    scaler = MinMaxScaler()
    df[feature_cols] = scaler.fit_transform(df[feature_cols])

    # Save preprocessed data back to GCS/local 
    save_csv(df, "gs://tractor-health-monitoring-bucket/data/combined_log_preprocessed.csv")

    # Split data
    X_train, X_test, y_train, y_test = train_test_data_split(df)

    # Save splits to GCS/local 
    save_csv(pd.concat([X_train, y_train], axis=1), "gs://tractor-health-monitoring-bucket/data/train_data.csv")
    save_csv(pd.concat([X_test, y_test], axis=1), "gs://tractor-health-monitoring-bucket/data/test_data.csv")

    return df, scaler

# -----------------------------
# For local quick test
# -----------------------------
if __name__ == "__main__":
    # Can pass local CSV path here too
    # local: "/home/pi/tractor-health-monitoring/edge/data_collector/combined_log.csv"
    test_path = "gs://tractor-health-monitoring-bucket/data/combined_log.csv"
    preprocess(test_path)
